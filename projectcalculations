library(class)
library(ggplot2)

install.packages("ggplot2")

df <- read.csv("/Users/jeffmilewski/Dropbox/Data_Science/Final_Project/df3data.csv", header = TRUE, sep = ",")

cor.test(df)

lm(df) # liner model

pairs() # A matrix of scatter plots is produced


fit <- lm(big ~ ask, df)
plot(pairs)

fit <- lm(pairs ~ ped, df)
plot(pairs ~ ped, df)
abline(fit, col="red")

summary(ols <- lm(crime ~ poverty + single, data = jeff_sample.csv))

fit2 <- lm(pairs ~ poly(ped, 2), df)
points(df$ped, predict(fit2), col="blue", type="l")

rmse(sim, obs, ...)

## Default S3 method:
rmse(sim, obs, na.rm=TRUE, ...)

## S3 method for class 'data.frame'
rmse(sim, obs, na.rm=TRUE, ...)

## S3 method for class 'matrix'
rmse(sim, obs, na.rm=TRUE, ...)

## S3 method for class 'zoo'
rmse(sim, obs, na.rm=TRUE, ...)

fit3 <- lm(pairs ~ poly(ped, 3), df)
points(df$ped, predict(fit3), col="orange", type="l")

anova(fit, fit2, fit3, fit4)

fit4 <- lm(pairs ~ poly(ped, 4), df)
points(df$ped, predict(fit4), col="green", type="l")

fit <- lm(y ~ x1 + x2 + x3, data=mydata)
summary(fit) # show results

coefficients(fit) # model coefficients
confint(fit, level=0.95) # CIs for model parameters 
fitted(fit) # predicted values
residuals(fit) # 
anova(fit) # anova table 
vcov(fit) # covariance matrix for model parameters 
influence(fit) # regression diagnostics

# diagnostic plots 
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page 
plot(fit)

# compare models
fit1 <- lm(y ~ x1 + x2 + x3 + x4, data=mydata)
fit2 <- lm(y ~ x1 + x2)
anova(fit1, fit2)

# K-fold cross-validation
library(DAAG)
cv.lm(df=mydata, fit, m=3) # 3 fold cross-validation

# Assessing R2 shrinkage using 10-Fold Cross-Validation 

fit <- lm(y~x1+x2+x3,data=mydata) 

library(bootstrap)
# define functions 
theta.fit <- function(x,y){lsfit(x,y)}
theta.predict <- function(fit,x){cbind(1,x)%*%fit$coef} 

# matrix of predictors
X <- as.matrix(mydata[c("x1","x2","x3")])
# vector of predicted values
y <- as.matrix(mydata[c("y")]) 

results <- crossval(X,y,theta.fit,theta.predict,ngroup=10)
cor(y, fit$fitted.values)**2 # raw R2 
cor(y,results$cv.fit)**2 # cross-validated R2

# Stepwise Regression
library(MASS)
fit <- lm(y~x1+x2+x3,data=mydata)
step <- stepAIC(fit, direction="both")
step$anova # display results

# All Subsets Regression
library(leaps)
attach(mydata)
leaps<-regsubsets(y~x1+x2+x3+x4,data=mydata,nbest=10)
# view results 
summary(leaps)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic.
plot(leaps,scale="r2")
# plot statistic by subset size 
library(car)
subsets(leaps, statistic="rsq")

# Calculate Relative Importance for Each Predictor
library(relaimpo)
calc.relimp(fit,type=c("lmg","last","first","pratt"),
   rela=TRUE)

# Bootstrap Measures of Relative Importance (1000 samples) 
boot <- boot.relimp(fit, b = 1000, type = c("lmg", 
  "last", "first", "pratt"), rank = TRUE, 
  diff = TRUE, rela = TRUE)
booteval.relimp(boot) # print result
plot(booteval.relimp(boot,sort=TRUE)) # plot result
